{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aa91634-5f53-4629-bbb6-4e53bd7d0c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s5/rdg9kttj7n9f1wwq0lrqtz_c0000gn/T/ipykernel_17978/3193313789.py:1: DeprecationWarning: The module `kfp.v2` is deprecated and will be removed in a futureversion. Please import directly from the `kfp` namespace, instead of `kfp.v2`.\n",
      "  from kfp.v2 import dsl\n"
     ]
    }
   ],
   "source": [
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import (Output, Metrics, component, ClassificationMetrics)\n",
    "from kfp.v2 import compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63c51077-9217-4168-8a9e-95e7392392b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mlevydaniel/opt/miniconda3/envs/python3.10/lib/python3.10/site-packages/kfp/dsl/component_decorator.py:119: FutureWarning: The default base_image used by the @dsl.component decorator will switch from 'python:3.8' to 'python:3.9' on Oct 1, 2024. To ensure your existing components work with versions of the KFP SDK released after that date, you should provide an explicit base_image argument and ensure your component works as intended on Python 3.9.\n",
      "  return component_factory.create_component_from_func(\n"
     ]
    }
   ],
   "source": [
    "@component(\n",
    "packages_to_install=[\"google-cloud-aiplatform\",\"gcsfs\",\"xgboost\",\n",
    "                     \"category_encoders\",\"imblearn\",\"pandas\",\n",
    "                     \"google-cloud-storage\", \"scikit-learn\"]\n",
    ")\n",
    "def custom_training_job_component(\n",
    "    max_depth:int,\n",
    "    learning_rate:float,\n",
    "    n_estimators:int,\n",
    "    metrics: Output[Metrics]\n",
    "):\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score,confusion_matrix\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from category_encoders import HashingEncoder\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from xgboost import XGBClassifier\n",
    "    from google.cloud import storage\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(\"udemy-gcp-mlops\")\n",
    "\n",
    "    def load_data(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df\n",
    "\n",
    "    def preprocess_data(df):\n",
    "\n",
    "        df = df.drop(columns=['car', 'toCoupon_GEQ5min', 'direction_opp'])\n",
    "        df = df.fillna(df.mode().iloc[0])\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "        df_dummy = df.copy()\n",
    "        age_list = []\n",
    "        for i in df['age']:\n",
    "            if i == 'below21':\n",
    "                age = '<21'\n",
    "            elif i in ['21', '26']:\n",
    "                age = '21-30'\n",
    "            elif i in ['31', '36']:\n",
    "                age = '31-40'\n",
    "            elif i in ['41', '46']:\n",
    "                age = '41-50'\n",
    "            else:\n",
    "                age = '>50'\n",
    "            age_list.append(age)\n",
    "        df_dummy['age'] = age_list\n",
    "\n",
    "        df_dummy['passanger_destination'] = df_dummy['passanger'].astype(str) + '-' + df_dummy['destination'].astype(str)\n",
    "        df_dummy['marital_hasChildren'] = df_dummy['maritalStatus'].astype(str) + '-' + df_dummy['has_children'].astype(str)\n",
    "        df_dummy['temperature_weather'] = df_dummy['temperature'].astype(str) + '-' + df_dummy['weather'].astype(str)\n",
    "        df_dummy = df_dummy.drop(columns=['passanger', 'destination', 'maritalStatus', 'has_children', 'temperature','weather', 'Y'])\n",
    "\n",
    "        df_dummy = pd.concat([df_dummy, df['Y']], axis = 1)\n",
    "        df_dummy = df_dummy.drop(columns=['gender', 'RestaurantLessThan20'])\n",
    "        df_le = df_dummy.replace({\n",
    "            'expiration':{'2h': 0, '1d' : 1},\n",
    "            'age':{'<21': 0, '21-30': 1, '31-40': 2, '41-50': 3, '>50': 4},\n",
    "            'education':{'Some High School': 0, 'High School Graduate': 1, 'Some college - no degree': 2,\n",
    "                         'Associates degree': 3, 'Bachelors degree': 4, 'Graduate degree (Masters or Doctorate)': 5},\n",
    "            'Bar':{'never': 0, 'less1': 1, '1~3': 2, '4~8': 3, 'gt8': 4},\n",
    "            'CoffeeHouse':{'never': 0, 'less1': 1, '1~3': 2, '4~8': 3, 'gt8': 4}, \n",
    "            'CarryAway':{'never': 0, 'less1': 1, '1~3': 2, '4~8': 3, 'gt8': 4}, \n",
    "            'Restaurant20To50':{'never': 0, 'less1': 1, '1~3': 2, '4~8': 3, 'gt8': 4},\n",
    "            'income':{'Less than $12500':0, '$12500 - $24999':1, '$25000 - $37499':2, '$37500 - $49999':3,\n",
    "                      '$50000 - $62499':4, '$62500 - $74999':5, '$75000 - $87499':6, '$87500 - $99999':7,\n",
    "                      '$100000 or More':8},\n",
    "            'time':{'7AM':0, '10AM':1, '2PM':2, '6PM':3, '10PM':4}\n",
    "        })\n",
    "\n",
    "        x = df_le.drop('Y', axis=1)\n",
    "        y = df_le.Y\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def train_model(x_train, y_train, max_depth, learning_rate, n_estimators):\n",
    "        model = XGBClassifier(\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            n_estimators=n_estimators,\n",
    "            random_state=42,\n",
    "            use_label_encoder=False\n",
    "        )\n",
    "        model.fit(x_train, y_train)\n",
    "        return model\n",
    "\n",
    "    def evaluate_model(model, x_test, y_test, x_sm_train_hashing, y_sm_train):\n",
    "        y_pred = model.predict(x_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "\n",
    "        metrics.log_metric(\"accurancy\", accuracy)\n",
    "        metrics.log_metric(\"precision\", precision)\n",
    "        metrics.log_metric(\"recall\", recall)\n",
    "\n",
    "        return accuracy, precision, recall\n",
    "\n",
    "    def encode_features(x, n_components=27):\n",
    "        hashing_ros_enc = HashingEncoder(cols=['passanger_destination', 'marital_hasChildren', 'occupation', 'coupon',\n",
    "                                               'temperature_weather'], n_components=n_components).fit(x)\n",
    "        x_test_hashing = hashing_ros_enc.transform(x.reset_index(drop=True))\n",
    "        return x_test_hashing\n",
    "\n",
    "    def oversample_data(x_train_hashing, y_train):\n",
    "        sm = SMOTE(random_state=42)\n",
    "        x_sm_train_hashing, y_sm_train = sm.fit_resample(x_train_hashing, y_train)\n",
    "        return x_sm_train_hashing, y_sm_train\n",
    "\n",
    "    input_file = \"gs://udemy-gcp-mlops/coupon-recommendation/in-vehicle-coupon-recommendation.csv\"\n",
    "    df = load_data(input_file)\n",
    "    x, y = preprocess_data(df)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    x_train.fillna(x_train.mode().iloc[0], inplace=True)\n",
    "    x_test.fillna(x_train.mode().iloc[0], inplace=True)\n",
    "    \n",
    "    x_train_hashing = encode_features(x_train)\n",
    "    x_test_hashing = encode_features(x_test)\n",
    "    x_sm_train_hashing, y_sm_train = oversample_data(x_train_hashing, y_train)\n",
    "\n",
    "    pipeline = train_model(x_sm_train_hashing, y_sm_train, max_depth, learning_rate, n_estimators)\n",
    "    evaluate_model(pipeline, x_test_hashing, y_test, x_sm_train_hashing, y_sm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f18b6c09-2cf4-4ae5-94d2-29d3ac954367",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"hyperparameter-model-training\")\n",
    "def pipeline(\n",
    "    max_depth:int,\n",
    "    learning_rate:float,\n",
    "    n_estimators:int\n",
    "    ):\n",
    "    custom_training_job_component(\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators\n",
    "    )\n",
    "\n",
    "compiler.Compiler().compile(pipeline_func=pipeline, package_path=\"experiment-pipeline.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c46e8d77-7725-46e0-97c1-2c228f5d0922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/936546808722/locations/us-central1/pipelineJobs/hyperparameter-model-training-20240908161405\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/936546808722/locations/us-central1/pipelineJobs/hyperparameter-model-training-20240908161405')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/hyperparameter-model-training-20240908161405?project=936546808722\n",
      "Associating projects/936546808722/locations/us-central1/pipelineJobs/hyperparameter-model-training-20240908161405 to Experiment: xgboost-hyperparameter-experiment\n",
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/936546808722/locations/us-central1/pipelineJobs/hyperparameter-model-training-20240908161415\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/936546808722/locations/us-central1/pipelineJobs/hyperparameter-model-training-20240908161415')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/hyperparameter-model-training-20240908161415?project=936546808722\n",
      "Associating projects/936546808722/locations/us-central1/pipelineJobs/hyperparameter-model-training-20240908161415 to Experiment: xgboost-hyperparameter-experiment\n",
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/936546808722/locations/us-central1/pipelineJobs/hyperparameter-model-training-20240908161423\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/936546808722/locations/us-central1/pipelineJobs/hyperparameter-model-training-20240908161423')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/hyperparameter-model-training-20240908161423?project=936546808722\n",
      "Associating projects/936546808722/locations/us-central1/pipelineJobs/hyperparameter-model-training-20240908161423 to Experiment: xgboost-hyperparameter-experiment\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "EXPERIMENT_NAME = \"xgboost-hyperparameter-experiment\"\n",
    "PIPELINE_ROOT = \"gs://udemy-gcp-mlops/coupon-pipeline-experiment\"\n",
    "\n",
    "runs = [\n",
    "    {\"max_depth\": 4, \"learning_rate\": 0.2, \"n_estimators\": 10},\n",
    "    {\"max_depth\": 5, \"learning_rate\": 0.3, \"n_estimators\": 20},\n",
    "    {\"max_depth\": 3, \"learning_rate\": 0.1, \"n_estimators\": 30}\n",
    "]\n",
    "\n",
    "for i, run in enumerate(runs):\n",
    "    job = aiplatform.PipelineJob(\n",
    "        display_name=f\"{EXPERIMENT_NAME}-pipeline-run-{i}\",\n",
    "        template_path=\"experiment-pipeline.json\",\n",
    "        pipeline_root=PIPELINE_ROOT,\n",
    "        parameter_values={\n",
    "            **run,\n",
    "        },\n",
    "    )\n",
    "    job.submit(experiment=EXPERIMENT_NAME)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
